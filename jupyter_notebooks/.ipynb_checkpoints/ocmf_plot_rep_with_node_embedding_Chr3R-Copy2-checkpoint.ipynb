{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as osp\n",
    "import networkx as nx\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_functions import eval_g_hat_with_DnX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2root = '../results_0905_logging/'\n",
    "K = 25\n",
    "version='Rr'\n",
    "iteration = 10000\n",
    "iid_sample = 20000\n",
    "chromo = 'chr3L'\n",
    "expr_name = f'{chromo}_drosophila_ChIA_Drop_0.1_PASS'\n",
    "prefix = f'{expr_name}_{iid_sample}_MCMC_pivot_K_{K}_iter_{iteration}'\n",
    "# prefix = f'{expr_name}_{iid_sample}_K_{K}_iter_{iteration}'\n",
    "# p2nmf_dict = osp.join(p2root, f'{prefix}_nmf_centroid_df')\n",
    "# p2cmf_dict = osp.join(p2root, f'{prefix}_cmf_centroid_df')\n",
    "# p2omf_dict = osp.join(p2root, f'{prefix}_omf_centroid_df')\n",
    "\n",
    "p2ocmf_dict = osp.join(p2root, f'{version}_{prefix}_ocmf_centroid_df')\n",
    "p2representative_regions = osp.join(p2root, f'{version}_{prefix}_x_hat_df')\n",
    "p2A_t = osp.join(p2root, f'A_t_{version}_{prefix}_ocmf.csv')\n",
    "p2W_hat = osp.join(p2root, f'W_hat_{version}_{prefix}_ocmf.csv')\n",
    "p2X = osp.join(p2root, f'{prefix}_X_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_pickle(p2X)\n",
    "# nmf_dict = pd.read_pickle(p2nmf_dict)\n",
    "# cmf_dict = pd.read_pickle(p2cmf_dict)\n",
    "# omf_dict = pd.read_pickle(p2omf_dict)\n",
    "ocmf_dict = pd.read_pickle(p2ocmf_dict)\n",
    "rep_region = pd.read_pickle(p2representative_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hat = np.loadtxt(p2W_hat, delimiter=',')\n",
    "A_t = np.loadtxt(p2A_t, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(W_hat > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_region.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_row(ax, row, k = 21, threshold = 1, title = ''):\n",
    "    row_np = np.array(row)\n",
    "    if threshold is not None:\n",
    "        bin_row = (row_np >= threshold).astype(int)\n",
    "        bin_row_mat = bin_row.reshape(k, k)\n",
    "    else:\n",
    "        bin_row_mat = row_np.reshape(k, k)\n",
    "    \n",
    "    ax.imshow(bin_row_mat, cmap = 'Greys')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    return bin_row_mat, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plot_one_row(ax, X_df.loc[5], title = 'row_5')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df_in_grid(df_in, grid_size = (2, 5), figsize = (10, 4), \n",
    "                    k = 21, threshold = 1, title_prefix = 'row', title = '', \n",
    "                   sub_titles = None, p2savefig = None):\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    axes = fig.subplots((*grid_size))\n",
    "    \n",
    "    for row_idx in range(grid_size[0]):\n",
    "        for col_idx in range(grid_size[1]):\n",
    "            ax = axes[row_idx][col_idx]\n",
    "            \n",
    "            idx = row_idx * grid_size[1] + col_idx\n",
    "            if idx < df_in.shape[0]:\n",
    "                cur_row = df_in.iloc[idx]\n",
    "            else:\n",
    "                cur_row = np.zeros_like(df_in.iloc[0].values)\n",
    "            \n",
    "            if sub_titles is None:\n",
    "                subtitle =  f'{title_prefix}_{idx}'\n",
    "            else:\n",
    "                if idx < len(sub_titles):\n",
    "                    subtitle = sub_titles[idx]\n",
    "                else:\n",
    "                    subtitle = ''\n",
    "                \n",
    "            plot_one_row(ax, cur_row, k = k, threshold= threshold, title = subtitle)\n",
    "    plt.suptitle(title, y = 1.05)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if p2savefig is None:\n",
    "        plt.show()    \n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.savefig(p2savefig)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_in_grid(X_df.loc[np.random.choice(X_df.index, 10)], title_prefix= 'random_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# online cvxMF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = [x for x in ocmf_dict.columns if 'label' not in x]\n",
    "ocmf_dict_val_df = ocmf_dict[feature]\n",
    "ocmf_dict_val_df.stack().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importance_from_At(A_t):\n",
    "    diag = A_t.diagonal()\n",
    "    sum_diag = sum(diag)\n",
    "    score = diag / sum_diag\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_score = get_importance_from_At(A_t)\n",
    "subtitles = [f'online cvxNDL\\n dictionaries {x}\\n score {importance_score[x]:.2f}' for x in range(ocmf_dict_val_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descending_order_of_At = importance_score.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_score[descending_order_of_At]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_df_in_grid(ocmf_dict_val_df, threshold = 0.6, \n",
    "#                 grid_size = (5, 5), figsize = (10, 10),\n",
    "#                 sub_titles= subtitles,\n",
    "#                 title = 'online cvxNDL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sorted dictionary by importance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ocmf_dict_val_df_by_At = ocmf_dict_val_df.loc[descending_order_of_At]\n",
    "sorted_subtitles_by_At = [subtitles[i] for i in descending_order_of_At]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarized dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# p2saved = f'/data/shared/jianhao/online_cvxNDL_results/{chromo}'\n",
    "# if not osp.isdir(p2saved):\n",
    "#     os.makedirs(p2saved)\n",
    "    \n",
    "# plot_df_in_grid(sorted_ocmf_dict_val_df_by_At, threshold = 0.6, \n",
    "#                 grid_size = (5, 5), figsize = (10, 10),\n",
    "#                 sub_titles= sorted_subtitles_by_At,\n",
    "#                 title = 'online cvxNDL',\n",
    "#                p2savefig=osp.join(p2saved, f'{chromo}_all_dictionaries_updated_0905'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw dicitonaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_in_grid(sorted_ocmf_dict_val_df_by_At, threshold = None, \n",
    "                grid_size = (5, 5), figsize = (10, 10),\n",
    "                sub_titles= sorted_subtitles_by_At,\n",
    "                title = f'online cvxNDL: {chromo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot convex hull of representative regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cvx_hull(ax, df_in, weight = None, k = 21, title = ''):\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.subplots()\n",
    "    \n",
    "    if weight is None:\n",
    "        average_row = df_in.mean(axis = 0).values\n",
    "    else:\n",
    "        average_row = (df_in * weight.reshape(-1, 1)).sum(axis = 0).values\n",
    "    bin_row_mat = average_row.reshape(k, k)\n",
    "\n",
    "    ax.imshow(bin_row_mat, cmap = 'Greys')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W_hat = pd.DataFrame(data = W_hat, columns = [f'w_cluster_{x}' for x in range(W_hat.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descending_order_of_At"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dictionaries in importance score order. Also plot the representative regions by their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in descending_order_of_At:\n",
    "    cur_label = f'group {i}'\n",
    "    df_rep = rep_region[rep_region.label == cur_label]\n",
    "    df_rep_val_df = df_rep[feature]\n",
    "\n",
    "    dict_row = ocmf_dict[ocmf_dict.label == f'ocmf: type {i + 1}']\n",
    "    dict_row = dict_row[feature]\n",
    "    fig = plt.figure(figsize=(8, 40))\n",
    "    ax = fig.subplots(1, 2)\n",
    "    # plot the dictionary, which is also the convex centroid.\n",
    "#     plot_one_row(ax[0], row = dict_row, \n",
    "#                  title = f'online cvxMF \\ndictionary {i}\\nscore = {importance_score[i]:.2f}', \n",
    "#                  threshold= 0.8)\n",
    "    # plot the average of representatives. \n",
    "    plot_cvx_hull(ax[0], df_rep_val_df, weight = None,\n",
    "                 title = f'average of \\nrep region {i}')\n",
    "    \n",
    "    cvx_weight = df_W_hat[rep_region.label == cur_label].values[:, i]\n",
    "    descending_order_cvx_weight = cvx_weight.argsort()[::-1]\n",
    "    \n",
    "    plot_cvx_hull(ax[1], df_rep_val_df, weight = cvx_weight,\n",
    "                  title = f'convex centroid \\nof rep region {i}')\n",
    "#     plot_cvx_hull(ax[2], df_rep_val_df, weight = None,\n",
    "#                   title = f'cvx hull \\nof rep region {i}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    sub_titles = [f'rep_{x}, \\nweight = {cvx_weight[x]:.2f}' \\\n",
    "                  for x in descending_order_cvx_weight]\n",
    "    \n",
    "    # reorder df_rep by their weights\n",
    "    sorted_df_rep_val_df_by_cvx_weight = df_rep_val_df.iloc[descending_order_cvx_weight]\n",
    "    \n",
    "    p2saved = f'/data/shared/jianhao/online_cvxNDL_results/{chromo}'\n",
    "    if not osp.isdir(p2saved):\n",
    "        os.makedirs(p2saved)\n",
    "    plot_df_in_grid(sorted_df_rep_val_df_by_cvx_weight.head(10), threshold = 1, \n",
    "                    sub_titles = sub_titles, title = f'dictionary {i}', \n",
    "                   p2savefig= osp.join(p2saved, f'representatives_of_dictionary_{i}_updated_0905_MCMC_pivot'))\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Get subgraph node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expr_name, iid_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p2raw_data = '/data/shared/jianhao/online_cvxNDL_data/new_data_with_node_id/'\n",
    "# p2raw_data = '/data/shared/jianhao/online_cvxNDL_data/updated_0905_data_with_node_id/'\n",
    "\n",
    "# p2emb = osp.join(p2raw_data, f'df_{expr_name}_{iid_sample}_sample_node_matrix')\n",
    "# p2raw_data = osp.join(p2raw_data, f'df_{expr_name}_{iid_sample}')\n",
    "\n",
    "p2raw_data = '/data/shared/jianhao/online_cvxNDL_data/updated_0905_data_with_node_id'\n",
    "p2emb = osp.join(p2raw_data, f'df_{expr_name}_{iid_sample}_MCMC_pivot_sample_node_matrix')\n",
    "p2raw_data = osp.join(p2raw_data, f'df_{expr_name}_{iid_sample}_MCMC_pivot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node_all = pd.read_pickle(p2emb)\n",
    "df_subgraph_all = pd.read_pickle(p2raw_data).drop(columns = ['label'])\n",
    "# df_subgraph_all_old = pd.read_pickle(p2raw_data_old).drop(columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_node_all = df_node_all.applymap(lambda s: s.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check which dataset used in training.\n",
    "if use old subgraph, then subgraph may not have correponding node embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if (X_df.values == df_subgraph_all_old.values).all():\n",
    "#     print('>>> used old dataset without node embedding!!!! Change later on.')\n",
    "#     df_raw_data = df_subgraph_all_old\n",
    "#     warning_flag = True\n",
    "#     df_raw_data_matched_emb = df_subgraph_all\n",
    "    \n",
    "if (X_df.values == df_subgraph_all.values).all():\n",
    "    print('>>> used new dataset with node embeddings. GOOD to go.')\n",
    "    df_raw_data = df_subgraph_all\n",
    "    warning_flag = False\n",
    "    df_raw_data_matched_emb = df_subgraph_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. df_raw_data will always be the input data. So df_rep.isin(df_raw_data) == True. \n",
    "only case is that when used old data:\n",
    "\n",
    "=> **df_node_emb** and **df_raw_data** does not match. \n",
    "\n",
    "### 2. df_raw_data_matched_emb will always matched the node embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw_data.shape, df_raw_data_matched_emb.shape, df_node_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "# Each represetative, get subgraph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_rows(row1, row2, titles = ['row1', 'row2']):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    axes = fig.subplots(1, 2)\n",
    "\n",
    "    plot_one_row(axes[0], row1, title = titles[0], threshold= None)\n",
    "    plot_one_row(axes[1], row2, title = titles[1], threshold= None)    \n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_arc_of_graph(H_directed, pos, ax = None, p2savefig = None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize = (20, 3))\n",
    "\n",
    "    nx.draw_networkx_nodes(H_directed, pos, \n",
    "                           node_size = 100, \n",
    "                           ax = ax)\n",
    "    nx.draw_networkx_edges(H_directed, pos, \n",
    "                           connectionstyle='arc3,rad=0.3', \n",
    "                           arrowsize= 0.1,\n",
    "                           ax = ax)\n",
    "\n",
    "    # skip some value of nodes that are close to each other.\n",
    "    old_x_value = -100\n",
    "    for value, loc in pos.items():\n",
    "        x, y = loc \n",
    "        if (x - old_x_value) < 3:\n",
    "            continue\n",
    "        old_x_value = x\n",
    "        ax.text(x, y - 20, value,\n",
    "                rotation = 315)\n",
    "\n",
    "    plt.ylim(-20, 100)\n",
    "    if p2savefig is None:    \n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(p2savefig)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W_hat.shape, rep_region.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvx_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dictionary + rep + arc plot of rep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cluster in descending_order_of_At:\n",
    "    cur_importance_score = importance_score[cluster]\n",
    "    # get current dictionary row from for the current cluster with descending importance score.\n",
    "    dict_row = ocmf_dict[ocmf_dict.label == f'ocmf: type {cluster + 1}']\n",
    "    dict_row = dict_row[feature]\n",
    "    \n",
    "    # get representative regions for the current cluster.\n",
    "    cur_label = f'group {cluster}'\n",
    "    df_rep_val_df = rep_region[rep_region.label == cur_label].drop(columns = ['label'])\n",
    "    \n",
    "    # Find convex weight for each rep. in the corresponding column of cvx_weight, and the selected \n",
    "    # representative rows. \n",
    "    # df_W_hat is a column vector matrix. Each column is the weight for a cluster.\n",
    "    cvx_weight = df_W_hat[rep_region.label == cur_label].values[:, cluster]\n",
    "    descending_order_cvx_weight = cvx_weight.argsort()[::-1]\n",
    "    \n",
    "    # sort representative by their cvx weights. \n",
    "    sorted_df_rep_val_df_by_cvx_weight = df_rep_val_df.iloc[descending_order_cvx_weight]\n",
    "    print('cluster :', cluster)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sorted_df_rep_val_df_by_cvx_weight.iterrows()):\n",
    "\n",
    "        row_in = row.values\n",
    "        cur_rep_idx = descending_order_cvx_weight[idx]\n",
    "        cur_weight = cvx_weight[cur_rep_idx]\n",
    "        \n",
    "        print('-' * 7, f'cluster {cluster}, rep {cur_rep_idx}, pos in {idx}', '-' * 7)\n",
    "        \n",
    "        if warning_flag:\n",
    "            # even though used old dataset, try to find if matching in new dataset exists.\n",
    "            # always true: df_raw_data == X_df != df_raw_data_matched_emb\n",
    "            sample_idx_in_subgraphs = (df_raw_data_matched_emb == row_in).all(axis = 1)\n",
    "            samples_from_df_raw_data = df_raw_data_matched_emb.loc[sample_idx_in_subgraphs]\n",
    "            \n",
    "            if len(samples_from_df_raw_data) == 0:\n",
    "#                 print('no match of row adj in new dataset with embedding. Use OLD dataset')\n",
    "                sample_idx_in_subgraphs = (df_raw_data == row_in).all(axis = 1)\n",
    "                samples_from_df_raw_data = df_raw_data.loc[sample_idx_in_subgraphs]\n",
    "                \n",
    "            \n",
    "        else:\n",
    "            # no warning sign. we are using new dataset so there is no error.\n",
    "            # df_raw_data == X_df == df_raw_data_matched_emb.\n",
    "            sample_idx_in_subgraphs = (df_raw_data == row_in).all(axis = 1)\n",
    "            samples_from_df_raw_data = df_raw_data.loc[sample_idx_in_subgraphs]\n",
    "        \n",
    "        # In case there are multiple samples with same weight matrices, select the first one.\n",
    "        samples_from_df_raw_data = samples_from_df_raw_data.iloc[0]\n",
    "        \n",
    "# ----------\n",
    "#         tmp_samples_from_df_raw_data_matched_emb = df_raw_data_matched_emb.loc[sample_idx_in_subgraphs]                \n",
    "#         sample_diff = np.sum(abs(samples_from_df_raw_data - tmp_samples_from_df_raw_data_matched_emb).values)\n",
    "#         if sample_diff > 0:\n",
    "#             pass\n",
    "# #             print(f'sample difference in old dataset and new dataset for the same row_in: {sample_diff}')\n",
    "# #             titles = ['row in new dataset', 'row in old dataset']\n",
    "# #             plot_two_rows(tmp_samples_from_df_raw_data_matched_emb, \n",
    "# #                          samples_from_df_raw_data, \n",
    "# #                          titles)\n",
    "# ----------\n",
    "\n",
    "        # In each cluster, for each representative, draw the dictionary, and the representative.\n",
    "        titles = [f'dictionary {cluster}\\nscore: {cur_importance_score:.2f}', \n",
    "                  f'representatative {cur_rep_idx}\\nweight: {cur_weight:.2f}']\n",
    "        plot_two_rows(dict_row, samples_from_df_raw_data, titles)\n",
    "        \n",
    "        \n",
    "        # Get node embeddings. \n",
    "        node_embedding_of_samples = df_node_all.loc[sample_idx_in_subgraphs].iloc[0].values\n",
    "        \n",
    "        # Create networkx graph from the samples adjacency matrix. \n",
    "        Adj = samples_from_df_raw_data.values.reshape(21, 21)\n",
    "        G = nx.from_numpy_matrix(Adj, )\n",
    "        \n",
    "        # Each node has its node embedding id, from: node_embedding_of_samples\n",
    "        node_name_map = {x:node_embedding_of_samples[x] for x in range(len(node_embedding_of_samples))}\n",
    "        G = nx.relabel.relabel_nodes(G, node_name_map)\n",
    "        \n",
    "        # Get nodes and edges from G, reorder nodes by ascending order of node embedding. \n",
    "        nodes = list(G.nodes(data = True))\n",
    "        edges = list(G.edges(data = True))\n",
    "        \n",
    "        node_pos = np.array([int(x[0][1:]) for x in nodes])\n",
    "        new_node_order = node_pos.argsort()\n",
    "        \n",
    "        new_node_pos = node_pos[new_node_order]\n",
    "        new_nodes = [nodes[i] for i in new_node_order]\n",
    "        \n",
    "        # create position for reordered nodes.\n",
    "        min_node_pos = min(new_node_pos)\n",
    "        max_node_pos = max(new_node_pos)\n",
    "        node_pos_span = max_node_pos - min_node_pos\n",
    "\n",
    "        pos = {new_nodes[i][0] : ((new_node_pos[i] - min_node_pos) / node_pos_span * 100, 0) \\\n",
    "               for i in range(len(nodes))}\n",
    "        \n",
    "        # change edges to same order between two vertices. i.e. n1 > n2.\n",
    "        backward_edge = lambda edge: (int(edge[0][1:]) < int(edge[1][1:]))\n",
    "        flip_nodes = lambda edge: (edge[1], edge[0], edge[2]) if backward_edge(edge) else edge\n",
    "        new_edges = [flip_nodes(x) for x in edges]\n",
    "        \n",
    "        # Create new graph H, from the new nodes, and same edges as G. \n",
    "        H_directed = nx.DiGraph()\n",
    "        H_directed.add_nodes_from(new_nodes)\n",
    "        H_directed.add_edges_from(new_edges)\n",
    "        \n",
    "        p2saved = f'/data/shared/jianhao/online_cvxNDL_results/{chromo}/representatvies_edge_list_updated_0905_MCMC_pivot_train_iter_10k/dictionary_{cluster}'\n",
    "        if not osp.isdir(p2saved):\n",
    "            os.makedirs(p2saved)\n",
    "        draw_arc_of_graph(H_directed, pos, \n",
    "                          p2savefig=osp.join(p2saved, \n",
    "                                             f'arc_plot_dictionary_{cluster}_rep_{cur_rep_idx}'))\n",
    "        plt.close()\n",
    "        \n",
    "        p2edge_list = osp.join(p2saved, \n",
    "                              f'edge_list_dicitonary_{cluster}_rep_{cur_rep_idx}.txt')\n",
    "        with open(p2edge_list, 'w') as f:\n",
    "            for line in new_edges:\n",
    "                f.write(','.join(line[:2]))\n",
    "                f.write('\\n')\n",
    "        \n",
    "        print('-' * 7, f'cluster {cluster}, rep {cur_rep_idx}, pos in {idx}', '-' * 7)\n",
    "        \n",
    "#         break\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randomly select original samples as representatives for each dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in descending_order_of_At:\n",
    "    \n",
    "    for cur_rep_idx in range(10):\n",
    "        random_idx = np.random.choice(len(df_raw_data))\n",
    "        samples_from_df_raw_data = df_raw_data.loc[random_idx]\n",
    "        \n",
    "        # Get node embeddings. \n",
    "        node_embedding_of_samples = df_node_all.loc[random_idx]\n",
    "        \n",
    "        # Create networkx graph from the samples adjacency matrix. \n",
    "        Adj = samples_from_df_raw_data.values.reshape(21, 21)\n",
    "        G = nx.from_numpy_matrix(Adj, )\n",
    "        \n",
    "        # Each node has its node embedding id, from: node_embedding_of_samples\n",
    "        node_name_map = {x:node_embedding_of_samples[x] for x in range(len(node_embedding_of_samples))}\n",
    "        G = nx.relabel.relabel_nodes(G, node_name_map)\n",
    "        \n",
    "        # Get nodes and edges from G, reorder nodes by ascending order of node embedding. \n",
    "        nodes = list(G.nodes(data = True))\n",
    "        edges = list(G.edges(data = True))\n",
    "        \n",
    "        node_pos = np.array([int(x[0][1:]) for x in nodes])\n",
    "        new_node_order = node_pos.argsort()\n",
    "        \n",
    "        new_node_pos = node_pos[new_node_order]\n",
    "        new_nodes = [nodes[i] for i in new_node_order]\n",
    "        \n",
    "        # create position for reordered nodes.\n",
    "        min_node_pos = min(new_node_pos)\n",
    "        max_node_pos = max(new_node_pos)\n",
    "        node_pos_span = max_node_pos - min_node_pos\n",
    "\n",
    "        pos = {new_nodes[i][0] : ((new_node_pos[i] - min_node_pos) / node_pos_span * 100, 0) \\\n",
    "               for i in range(len(nodes))}\n",
    "        \n",
    "        # change edges to same order between two vertices. i.e. n1 > n2.\n",
    "        backward_edge = lambda edge: (int(edge[0][1:]) < int(edge[1][1:]))\n",
    "        flip_nodes = lambda edge: (edge[1], edge[0], edge[2]) if backward_edge(edge) else edge\n",
    "        new_edges = [flip_nodes(x) for x in edges]\n",
    "        \n",
    "        # Create new graph H, from the new nodes, and same edges as G. \n",
    "        H_directed = nx.DiGraph()\n",
    "        H_directed.add_nodes_from(new_nodes)\n",
    "        H_directed.add_edges_from(new_edges)\n",
    "        \n",
    "        p2saved = f'/data/shared/jianhao/online_cvxNDL_results/{chromo}/random_rep_edge_list/dictionary_{cluster}'\n",
    "        if not osp.isdir(p2saved):\n",
    "            os.makedirs(p2saved)\n",
    "        draw_arc_of_graph(H_directed, pos, \n",
    "                          p2savefig=osp.join(p2saved, \n",
    "                                             f'arc_plot_dictionary_{cluster}_rep_{cur_rep_idx}'))\n",
    "        plt.close()\n",
    "        \n",
    "        p2edge_list = osp.join(p2saved, \n",
    "                              f'edge_list_dicitonary_{cluster}_rep_{cur_rep_idx}.txt')\n",
    "        with open(p2edge_list, 'w') as f:\n",
    "            for line in new_edges:\n",
    "                f.write(','.join(line[:2]))\n",
    "                f.write('\\n')\n",
    "        \n",
    "        \n",
    "#         break\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
